namespace zprol.lang.memory;

using zprol.lang.linux.amd64;
using zprol.lang.collection;
using zprol.lang;

class _mem_item {
    uint32 data;
}

class _mem_item_malloc { // 20 bytes
    uint32 next; // offset
    uint32 prev; // offset
    _mem_element parent;
    uint32 data;
}

class _mem_item_mmap { // 8 bytes
    uint32 data2;
    uint32 data;
}

class _mem_element { // 24 bytes
    _mem_element next;
    _mem_element prev;
    uint64 biggest_available_segment;
}

List _mem_elements;

byte[] malloc(ulong length) {
    if(length >= 0x80000 - 24 - 20) {
        length = length + 8;
        _mem_item_mmap data = (_mem_item_mmap!) mmap_alloc(length);
        data.data = (uint32) ((length & 0x7fffffff) | 0x80000000);
        data.data2 = (uint32) (length >> 31);
        return (byte[]!) ((ulong!) data + 8);
    }
    if(_mem_elements == null) {
        List i = (List!) mmap_alloc(24 + 509 * 8);
        i.usedLength = 0;
        i.usableLength = 509;
        i.pointer = (uint64[]!) ((ulong!) i + 24);
        _mem_elements = i;
    }
    if(_mem_elements.usedLength == 0) {
        _mem_element i = (_mem_element!) mmap_alloc(0x80000);
        i.next = null;
        i.prev = null;
        i.biggest_available_segment = 0x80000 - 24;
        _mem_elements.add((uint64!) i);
        __malloc_init_element(i);
    }
    ulong i = 0;
    while(i < _mem_elements.usedLength) {
        _mem_element y = (_mem_element!) _mem_elements.get(i);
        if(y.biggest_available_segment >= length + 20) {
            return __malloc_from_element(y, length);
        }
        i = i + 1;
    }
    __malloc_ensure_element_storage();
    _mem_element j = (_mem_element!) mmap_alloc(0x80000);
    _mem_element last = (_mem_element!) _mem_elements.get(_mem_elements.usedLength - 1);
    j.next = null;
    last.next = j;
    j.prev = last;
    j.biggest_available_segment = 0x80000 - 24;
    _mem_elements.add((uint64!) j);
    __malloc_init_element(j);
    return __malloc_from_element(j, length);
}

void __malloc_ensure_element_storage() {
    if(_mem_elements.usedLength + 1 >= _mem_elements.usableLength) {
        List i = (List!) mmap_alloc(24 + _mem_elements.usableLength * 2 * 8);
        i.usedLength = _mem_elements.usedLength;
        i.usableLength = _mem_elements.usableLength * 2 + 3;
        i.pointer = (uint64[]!) ((ulong!) i + 24);
        uint64 j = 0;
        while(j < _mem_elements.usableLength) {
            i.pointer[j] = _mem_elements.pointer[j];
            j = j + 1;
        }
        munmap((ulong!) _mem_elements, 24 + _mem_elements.usableLength * 8);

        _mem_elements = i;
    }
}

void __malloc_init_element(_mem_element element) {
    _mem_item_malloc item = (_mem_item_malloc!) ((ulong!) element + 24);
    // flag 0x01 - item unused
    item.data = 0x01000000 | (0x80000 - 24);
    item.next = 0;
    item.prev = 0;
    item.parent = element;
}

byte[] __malloc_from_element(_mem_element element, uint64 length) {
    _mem_item_malloc c = (_mem_item_malloc!) ((ulong!)element + 24);
    while(c != null) {
        uint64 data = (uint64) c.data & 0xffffffff;
        uint64 flags = data >> 24;
        bool unused = (flags & (uint64)0x01) == (uint64) 1;
        uint64 clen = data & 0x00ffffff;
        if(unused) {
            if(clen >= length) {
                _mem_item_malloc n = (_mem_item_malloc!) ((ulong!) c + clen - length - 20); // set up the new item at the end of the current element
                n.data = (uint32) length;
                n.next = 0;

                if(c.next != 0) {
                    _mem_item_malloc next = (_mem_item_malloc!) ((ulong!) c + c.next);
                    next.prev = (uint32) ((uint64!) next - (uint64!) n);
                    n.next = (uint32) ((uint64!) next - (uint64!) n);
                }

                uint32 dist = (uint32) ((uint64!) n - (uint64!) c);
                n.prev = dist;
                c.next = dist;
                c.data = (uint32) (c.data - length - 20); // shouldn't underflow the flags if everything is correct
                n.parent = element;
                __malloc_recalculate_max_segment_size(element);
                return (byte[]!) ((ulong!) n + 20);
            }
        }
        if(c.next == 0) {
            return null; // somehow failed, even though the sizes should be correct, this shouldn't happen!
        }
        c = (_mem_item_malloc!) ((ulong!) c + c.next);
    }
    return null; // impossible
}

void __malloc_recalculate_max_segment_size(_mem_element element) {
    _mem_item_malloc c = (_mem_item_malloc!) ((ulong!)element + 24);
    uint64 biggest = 0;
    while(c != null) {
        uint64 data = (uint64) c.data & 0xffffffff;
        uint64 flags = data >> 24;
        bool unused = (flags & (uint64)0x01) == (uint64) 1;
        uint64 clen = data & 0x00ffffff;
        if(unused) {
            if(biggest < clen) => biggest = clen;
        }
        if(c.next == 0) {
            element.biggest_available_segment = biggest;
            break;
        }
        c = (_mem_item_malloc!) ((ulong!) c + c.next);
    }
}

void free(byte[] location) {
    _mem_item item = (_mem_item!) ((ulong!) location - 4);
    if((item.data & 0x80000000) != 0) {
        _mem_item_mmap mmap_item = (_mem_item_mmap!) ((ulong!) location - 8);
        ulong length = (mmap_item.data & 0x7fffffff) | ((ulong) mmap_item.data2 << 31);
        munmap((ulong!) item, length);
    }else {
        _mem_item_malloc malloc_item = (_mem_item_malloc!) ((ulong!) location - 20);
        _mem_element element = malloc_item.parent;
        malloc_item.data = malloc_item.data | 0x01000000;
        ulong containingLength = malloc_item.data & 0x00ffffff;
        _mem_item_malloc next_item = null;
        _mem_item_malloc prev_item = null;
        if(malloc_item.next != 0) {
            next_item = (_mem_item_malloc!) ((ulong!) malloc_item + malloc_item.next);
            if((next_item.data & 0x01000000) != 0) {
                containingLength = containingLength + (next_item.data & 0x00ffffff) + 20;
                if(next_item.next == 0) => next_item = null;
                else => next_item = (_mem_item_malloc!) ((ulong!) next_item + next_item.next);
            }
        }
        if(malloc_item.prev != 0) {
            prev_item = (_mem_item_malloc!) ((ulong!) malloc_item - malloc_item.prev);
            if((prev_item.data & 0x01000000) != 0) {
                containingLength = containingLength + (prev_item.data & 0x00ffffff) + 20;
                malloc_item = prev_item;
                if(prev_item.prev == 0) => prev_item = null;
                else => prev_item = (_mem_item_malloc!) ((ulong!) prev_item + prev_item.prev);
            }
        }
        if(next_item == null) => malloc_item.next = 0;
        else => malloc_item.next = (uint32) ((ulong!) next_item - (ulong!) malloc_item);
        if(prev_item == null) => malloc_item.prev = 0;
        else => malloc_item.prev = (uint32) ((ulong!) prev_item - (ulong!) malloc_item);
        malloc_item.data = (uint32) (0x01000000 | containingLength);
        if(element.biggest_available_segment < containingLength) => element.biggest_available_segment = containingLength;
    }
}

bool memory_compare(byte[] a, byte[] b, ulong length) {
    ulong i = 0;
    while(i < length) {
        if(a[i] != b[i]) => return false;
        i = i + 1;
    }
    return true;
}

byte[] mmap_alloc(uint64 length) => return mmap(0, length, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);

byte[] mmap(uint64 addr, uint64 length, uint64 protection, uint64 flags, uint64 fd, uint64 offset) =>
    return (byte[]!) syscall(SYSCALL_MMAP, addr, length, protection, flags, fd, offset);

void munmap(uint64 addr, uint64 length) => syscall(SYSCALL_MUNMAP, addr, length);

const int64 PROT_READ = 1;
const int64 PROT_WRITE = 2;

const int64 MAP_PRIVATE = 2;
const int64 MAP_SHARED = 4;
const int64 MAP_ANONYMOUS = 32;